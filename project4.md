Project 4 - Replication
========================================================

### Code and *Demonstration* Due - Monday April 23, 5PM

The goal of this project is to implement a replicated, fault tolerant version of the service you implemented for Project 3. There are two main requirements of your implementation:

1. **Fault Tolerance** - In a system with N data storage servers, you will tolerate the failure of up to N-1 nodes. As long as one data storage server is available, a client request will succeed.
2. **Read-My-Writes Consistency** - A front end will not receive data older than it has seen before if fresher data is available. If, for example, a client posts a message and then performs a read, the response the client receives must include the most recent messages unless all data storage servers storing the newest data have failed.

You have three implementation options:

### Strong Consistency

You may implement strong consistency using a passive replication scheme. Your service will be replaced by a primary server that receives all requests and synchronously replicates data to one or more secondary servers. Only after all secondaries have received the update will the primary reply to the front end, at which point the front end may reply to the client.

You will implement a mechanism for determining whether/when the primary replica has failed. Sending heartbeat messages among the replicas at a regular interval is the recommended approach. If the primary replica fails, you must do all of the following:

1. Elect a new primary from the remaining secondary replicas. For full credit, you must implement a distributed election algorithm such as the bully algorithm.
2. Resolve any inconsistencies. If the primary was in the process of a write operation when it failed, you must either ensure that the new data is replicated on all secondaries or remove the update from the secondaries that had received it.
3. Inform the front ends of the IP address of the new replica.

#### Other Details

Your implementation must allow new front ends and secondary replicas to be added at any time. New front ends and secondary replicas will be configured with the IP address of the current primary, but this is the only pre-configured information you may assume. You must implement a procedure for the primary to replicate the membership information. You may assume that the primary will not fail during this start-up procedure (or, if it does, an administrator will restart the process on the new node).

### Eventual Consistency

You may implement eventual consistency using a lazy replication scheme and vector timestamps. In the lazy replication scheme, front ends may contact any  service replica, at any time, for any type of request. For a write, a service replica may respond to the front end before the data has been replicated. Along with the response, the replica will provide its most recent vector timestamp. The front end will use this to ensure that it receives the freshest data possible when performing a read.

In the background, service replicas will propagate updates to all other replicas. When a front end sends a read request to a replica, it will provide the most recent timestamp it has seen. A replica will not respond until its timestamp is equal to or greater than the timestamp provided, unless the only replica containing the data with such a timestamp has failed.

Timestamps will also be used by the replicas to provide partial ordering of the data. Data returned by the replica will be ordered by vector timestamp, which means that writes that were initially handled by the same replica will be in chronological order. For the event service this means ordering the events, and for the user service it means ordering the tickets added for a user.

Your implementation must allow new front ends and service replicas to be added at any time. A new node will be configured with the IP address of one of the replicas. You will implement a procedure for propagating information about new nodes to all other nodes in the system.

You may implement your own procedure for determining which replica is contacted by a given front end for a given request, but your approach must meet two requirements: (1) as long as one replica is available any front end should be able to successfully complete a request and (2) load must be balanced among the replicas.

#### Other Details

You will need to design solutions to the following challenges:

1. Event and User IDs must be unique, therefore each replica will need to have a scheme for ensuring that it does not generate an ID that may be generated by a different replica for a different `/create` request.
2. Purchase and transfer of tickets may result in incorrect behavior in an eventually consistent system. In case of ticket purchase, if two replicas concurrently handle a request for the last ticket then both will reply that the purchase was successful even though one of the requests should have failed. In case of ticket transfer, if two replicas concurrently handle a request to transfer the last ticket to another usr then both will reply that the transfer was successful even though one of the requests should have failed. You do not need to *prevent* this situation, however your solution must be able to detect this situation; decide which request should be successful and which should fail; and output to your logs which request will need to be reverted. (You could imagine that the system would then contact the user to say that there was a system error and tickets are no longer available.)

### Design Your Own

You may design your own approach provided you meet the following requirements:

1. You schedule an in-person meeting to discuss your design with the professor. During this meeting, you will be informed of maximum possible grade you may receive given the level of difficulty of your approach.
2. You provide a (short) written description of your approach.
3. Your approach incorporates one or more of the algorithms discussed in class (e.g., causal ordering using vector clocks, mutual exclusion, dynamo,  election).


### Requirements

This is an individual assignment.

If you worked in a team for Project 3 then you may use the common code base you developed for the front end web server. You will, however, have to extend the front end functionality to work correctly for this assignment.

You are responsible for clearly demonstrating all functionality. This means you will need to implement clear logging to demonstrate how your algorithms works as well as test code to show how your program behaves under all conditions, including concurrent requests and failures. 

*A portion of your grade will be based on your test framework and you will not receive demonstration credit for any functionality that is not clearly demonstrated.* 

### Submission Requirements

1. All code and instructions for running must be submitted to your github repository by **Monday April 23, 5PM**.
2. All students must sign up for a demonstration to be completed by **Monday April 23, 5PM**. A sign-up sheet will be made available closer to the deadline. During your demonstration, you will be asked to do the following:
  - Run at least two instances of your web server on two different microcloud machines.
  - Run at least three instances of your service on three different microcloud  machines.
  - Provide an overview of your code design.
  - Show specific elements of your code and be prepared to answer questions about any portion of your code.
  - Demonstrate test cases that show your code works correctly.
     - Replication happens correctly and strong or eventual consistency is provided.
     - Your system recovers when any component fails.
     - New components (front ends or service replicas) can be added dynamically.


For full credit, make sure to follow all [Style Guidelines](https://github.com/CS682-S18/notes/blob/master/style.md). Points will be deducted for each violation.

Use the following link to create your private github repository for this assignment: [Project 4](https://classroom.github.com/a/8xaUhj7s)


### Grading Rubric

| Points | Criterion |
| ------ | -------- |  
| 10 | Style |  
| 20 | Code Design |  
| 10 | Testing Framework |  
| 10 | Demonstration - Code explanation |  
| 10 | Demonstration - Group membership |  
| 10 | Demonstration - Replication |  
| 10 | Demonstration - Dynamic addition of new front end/replica |  
| 10 | Demonstration - Node failure |  
| 10 | Demonstration - Concurrent requests |  

Partial credit may be awarded for partial functionality and/or partially correct design or style elements.

### Academic Dishonesty

Any work you submit is expected to be your own original work. If you use any web resources in developing your code you are strongly advised to cite those resources. The only exception to this rule is code that is posted on the class website. The URL of the resource you used in a comment in your code is fine. If I google even a single line of uncited code and find it on the internet you may get a 0 on the assignment or an F in the class. You may also get a 0 on the assignment or an F in the class if your solution is at all similar to that of any other student.
